llm:
  default_model: "o4-mini"
  temperature: 1
  max_tokens: 100000
  api_key: "your-api-key-here"
  base_url: "https://your-api-base-url"

lean:
  timeout: 30
  max_attempts: 1

proof:
  output_format: "markdown"
  include_steps: true
  verify_syntax: true